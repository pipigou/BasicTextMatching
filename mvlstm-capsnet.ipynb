{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import gc\n",
    "    \n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1000)\n",
    "from tensorflow.random import set_random_seed\n",
    "set_random_seed(1000)\n",
    "\n",
    "import pandas\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "# from keras.layers import Layer\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, Embedding, Conv1D, Concatenate, Flatten, Dropout, Dense, Bidirectional, Activation, GRU\n",
    "from keras.layers import MaxPooling1D, Conv2D, Flatten, Reshape, MaxPooling2D, LSTM, Lambda, Highway, Dot, Permute, Add\n",
    "from keras.models import Model, Sequential\n",
    "from keras.activations import softmax\n",
    "from keras.initializers import Constant, RandomNormal, RandomUniform\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns       \n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import  norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline \n",
    "\n",
    "#进行配置，使用30%的GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# 设置session\n",
    "KTF.set_session(session )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径\n",
    "ORIGINAL_FILE_PATH = \"../data/original_data/quora_duplicate_questions.tsv\"\n",
    "\n",
    "DATA_ALL_PATH = \"../data/all_data.txt\"\n",
    "\n",
    "DATA_TRAIN_PATH = \"../data/train.txt\"\n",
    "DATA_VALID_PATH = \"../data/valid.txt\"\n",
    "DATA_TEST_PATH = \"../data/test.txt\"\n",
    "\n",
    "MAPS_FILE_PATH = \"../data/maps.pkl\"\n",
    "\n",
    "# Glove文件\n",
    "WORD2VEC_PATH = \"../data/GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "# Model Path\n",
    "MODEL_PATH = \"../model/mvlstm-capsnet/mvlstm-capsnet-01.h5\"\n",
    "\n",
    "# 创建文件夹\n",
    "(file_path, file_name) = os.path.split(MODEL_PATH)\n",
    "if not os.path.exists(file_path):\n",
    "    os.mkdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(dict_path):\n",
    "    with open(dict_path, 'rb') as fr:\n",
    "        return pickle.load(fr)\n",
    "        \n",
    "def create_maps(dico):\n",
    "    item2id = dico\n",
    "    id2item = dict([val, key] for key, val in dico.items())\n",
    "    return item2id, id2item\n",
    "\n",
    "def read_file(fpath):\n",
    "    \"\"\"\n",
    "    读取文件，返回\n",
    "    \"\"\"\n",
    "    question1, question2, labels = [], [], []\n",
    "    with open(fpath, 'r', encoding=\"utf-8\") as fr:\n",
    "        for line in fr.readlines():\n",
    "            try:\n",
    "                q, k, l = line.strip().split('\\t')\n",
    "            except ValueError:\n",
    "                print(line)\n",
    "            question1.append(q)\n",
    "            question2.append(k)\n",
    "            labels.append(int(l))\n",
    "            \n",
    "    return question1, question2, labels\n",
    "\n",
    "def load_data(fpath, word_to_id, max_length=20):\n",
    "    \"\"\"\n",
    "    载入数据，并将其转化为id表示\n",
    "    \"\"\"\n",
    "    question1, question2, labels = read_file(fpath)\n",
    "    \n",
    "    q1_id, q2_id = [], []\n",
    "    for i in range(len(question1)):\n",
    "        q1= question1[i].split()\n",
    "        q2 = question2[i].split()\n",
    "        q1_id.append([word_to_id[x] for x in q1 if x in word_to_id])\n",
    "        q2_id.append([word_to_id[x] for x in q2 if x in word_to_id])\n",
    "\n",
    "    # 使用keras提供的pad_sequences来将文本pad为固定长度\n",
    "    x1_pad = keras.preprocessing.sequence.pad_sequences(q1_id, max_length, padding=\"post\")\n",
    "    x2_pad = keras.preprocessing.sequence.pad_sequences(q2_id, max_length, padding=\"post\")\n",
    "    labels = keras.utils.np_utils.to_categorical(labels)\n",
    "    \n",
    "    return x1_pad, x2_pad, labels\n",
    "    \n",
    "        \n",
    "def load_word2vec(embedding_path, word_index, embed_dim=300): \n",
    "    \"\"\"\n",
    "    载入预训练好的word2vec(Google-News)\n",
    "    \"\"\"\n",
    "    # 载入word2vec词向量\n",
    "    word2vec_dict = KeyedVectors.load_word2vec_format(embedding_path,binary=True)\n",
    "    \n",
    "    embedding_index = dict()\n",
    "    for word in word2vec_dict.wv.vocab:\n",
    "        embedding_index[word] = word2vec_dict.word_vec(word)\n",
    "    print('Load %s word vectors.' % len(embedding_index))\n",
    "    \n",
    "    all_embs = np.stack(list(embedding_index.values()))\n",
    "    # emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    emb_mean = np.mean(all_embs, axis=0)\n",
    "    vocab_size = len(word_index)\n",
    "    # 初始化权重\n",
    "    embedding_matrix = np.zeros((vocab_size+1, embed_dim))\n",
    "    gc.collect()\n",
    "    # 对权重矩阵进行赋值，未找到时用词向量平均值填充\n",
    "    for word, i in word_index.items():\n",
    "        if i < vocab_size + 1:\n",
    "            embedding_vector = embedding_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "            else:\n",
    "                embedding_matrix[i] = emb_mean\n",
    "    del embedding_index\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "dico = load_dict(MAPS_FILE_PATH)\n",
    "word_index, index_word = create_maps(dico)\n",
    "\n",
    "# 准备数据\n",
    "x1_train, x2_train, y_train = load_data(DATA_TRAIN_PATH, word_index)\n",
    "x1_valid, x2_valid, y_valid = load_data(DATA_VALID_PATH, word_index)\n",
    "x1_test, x2_test, y_test = load_data(DATA_TEST_PATH, word_index)\n",
    "\n",
    "embedding_matrix = load_word2vec(WORD2VEC_PATH, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# The following is another way to implement primary capsule layer. This is much slower.\\n# Apply Conv2D `n_channels` times and concatenate all capsules\\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\\n    outputs = []\\n    for _ in range(n_channels):\\n        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\\n        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\\n    outputs = layers.Concatenate(axis=1)(outputs)\\n    return layers.Lambda(squash)(outputs)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Some key layers used for constructing a Capsule Network. These layers can used to construct CapsNet on other dataset, \n",
    "not just on MNIST.\n",
    "*NOTE*: some functions can be implemented in multiple ways, I keep all of them. You can try them for yourself just by\n",
    "uncommenting them and commenting their counterparts.\n",
    "\n",
    "Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
    "\"\"\"\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras import initializers, layers\n",
    "\n",
    "\n",
    "class Length(layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
    "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
    "    inputs: shape=[None, num_vectors, dim_vector]\n",
    "    output: shape=[None, num_vectors]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
    "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
    "    masked Tensor.\n",
    "    For example:\n",
    "        ```\n",
    "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
    "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
    "        out = Mask()(x)  # out.shape=[8, 6]\n",
    "        # or\n",
    "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
    "            # compute lengths of capsules\n",
    "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
    "            # generate the mask which is a one-hot code.\n",
    "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
    "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
    "        # mask.shape=[None, num_capsule]\n",
    "        # masked.shape=[None, num_capsule * dim_capsule]\n",
    "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"\n",
    "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
    "    :param vectors: some vectors to be squashed, N-dim tensor\n",
    "    :param axis: the axis to squash\n",
    "    :return: a Tensor with same shape as input vectors\n",
    "    \"\"\"\n",
    "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
    "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
    "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
    "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
    "    \n",
    "    :param num_capsule: number of capsules in this layer\n",
    "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
    "    :param routings: number of iterations for the routing algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
    "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
    "        inputs_expand = K.expand_dims(inputs, 1)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
    "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
    "        # Regard the first two dimensions as `batch` dimension,\n",
    "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
    "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "\n",
    "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
    "        # The prior for coupling coefficient, initialized as zeros.\n",
    "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
    "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "\n",
    "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
    "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "            # The first two dimensions as `batch` dimension,\n",
    "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
    "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
    "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
    "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "                # The first two dimensions as `batch` dimension,\n",
    "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
    "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
    "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    \"\"\"\n",
    "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
    "    :param dim_capsule: the dim of the output vector of capsule\n",
    "    :param n_channels: the number of types of capsules\n",
    "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
    "    \"\"\"\n",
    "    output = Conv1D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv1d')(inputs)\n",
    "    outputs = Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# The following is another way to implement primary capsule layer. This is much slower.\n",
    "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    outputs = []\n",
    "    for _ in range(n_channels):\n",
    "        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
    "    outputs = layers.Concatenate(axis=1)(outputs)\n",
    "    return layers.Lambda(squash)(outputs)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "class Match(Layer):\n",
    "    \"\"\"Layer that computes a matching matrix between samples in two tensors.\n",
    "    # Arguments\n",
    "        normalize: Whether to L2-normalize samples along the\n",
    "            dot product axis before taking the dot product.\n",
    "            If set to True, then the output of the dot product\n",
    "            is the cosine proximity between the two samples.\n",
    "        **kwargs: Standard layer keyword arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalize=False, match_type='dot', **kwargs):\n",
    "        super(Match, self).__init__(**kwargs)\n",
    "        self.normalize = normalize\n",
    "        self.match_type = match_type\n",
    "        self.supports_masking = True\n",
    "        if match_type not in ['dot', 'mul', 'plus', 'minus', 'concat']:\n",
    "            raise ValueError('In `Match` layer, '\n",
    "                             'param match_type=%s is unknown.' % match_type)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Used purely for shape validation.\n",
    "        if not isinstance(input_shape, list) or len(input_shape) != 2:\n",
    "            raise ValueError('A `Match` layer should be called '\n",
    "                             'on a list of 2 inputs.')\n",
    "        self.shape1 = input_shape[0]\n",
    "        self.shape2 = input_shape[1]\n",
    "        if self.shape1[0] != self.shape2[0]:\n",
    "            raise ValueError(\n",
    "                'Dimension incompatibility '\n",
    "                '%s != %s. ' % (self.shape1[0], self.shape2[0]) +\n",
    "                'Layer shapes: %s, %s' % (self.shape1, self.shape2))\n",
    "        if self.shape1[2] != self.shape2[2]:\n",
    "            raise ValueError(\n",
    "                'Dimension incompatibility '\n",
    "                '%s != %s. ' % (self.shape1[2], self.shape2[2]) +\n",
    "                'Layer shapes: %s, %s' % (self.shape1, self.shape2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = inputs[0]\n",
    "        x2 = inputs[1]\n",
    "        if self.match_type in ['dot']:\n",
    "            if self.normalize:\n",
    "                x1 = K.l2_normalize(x1, axis=2)\n",
    "                x2 = K.l2_normalize(x2, axis=2)\n",
    "            output = K.tf.einsum('abd,acd->abc', x1, x2)\n",
    "            output = K.tf.expand_dims(output, 3)\n",
    "        elif self.match_type in ['mul', 'plus', 'minus']:\n",
    "            x1_exp = K.tf.stack([x1] * self.shape2[1], 2)\n",
    "            x2_exp = K.tf.stack([x2] * self.shape1[1], 1)\n",
    "            if self.match_type == 'mul':\n",
    "                output = x1_exp * x2_exp\n",
    "            elif self.match_type == 'plus':\n",
    "                output = x1_exp + x2_exp\n",
    "            elif self.match_type == 'minus':\n",
    "                output = x1_exp - x2_exp\n",
    "        elif self.match_type in ['concat']:\n",
    "            x1_exp = K.tf.stack([x1] * self.shape2[1], axis=2)\n",
    "            x2_exp = K.tf.stack([x2] * self.shape1[1], axis=1)\n",
    "            output = K.tf.concat([x1_exp, x2_exp], axis=3)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if not isinstance(input_shape, list) or len(input_shape) != 2:\n",
    "            raise ValueError('A `Match` layer should be called '\n",
    "                             'on a list of 2 inputs.')\n",
    "        shape1 = list(input_shape[0])\n",
    "        shape2 = list(input_shape[1])\n",
    "        if len(shape1) != 3 or len(shape2) != 3:\n",
    "            raise ValueError('A `Match` layer should be called '\n",
    "                             'on 2 inputs with 3 dimensions.')\n",
    "        if shape1[0] != shape2[0] or shape1[2] != shape2[2]:\n",
    "            raise ValueError('A `Match` layer should be called '\n",
    "                             'on 2 inputs with same 0,2 dimensions.')\n",
    "\n",
    "        if self.match_type in ['dot']:\n",
    "            output_shape = [shape1[0], shape1[1], shape2[1], 1]\n",
    "        elif self.match_type in ['mul', 'plus', 'minus']:\n",
    "            output_shape = [shape1[0], shape1[1], shape2[1], shape1[2]]\n",
    "        elif self.match_type in ['concat']:\n",
    "            output_shape = [shape1[0], shape1[1], shape2[1], shape1[2]+shape2[2]]\n",
    "\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'normalize': self.normalize,\n",
    "            'match_type': self.match_type,\n",
    "        }\n",
    "        base_config = super(Match, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def match(inputs, axes, normalize=False, match_type='dot', **kwargs):\n",
    "    \"\"\"Functional interface to the `Match` layer.\n",
    "    # Arguments\n",
    "        inputs: A list of input tensors (with exact 2 tensors).\n",
    "        normalize: Whether to L2-normalize samples along the\n",
    "            dot product axis before taking the dot product.\n",
    "            If set to True, then the output of the dot product\n",
    "            is the cosine proximity between the two samples.\n",
    "        **kwargs: Standard layer keyword arguments.\n",
    "    # Returns\n",
    "        A tensor, the dot product matching matrix of the samples \n",
    "        from the inputs.\n",
    "    \"\"\"\n",
    "    return Match(normalize=normalize, match_type=match_type, **kwargs)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dico)\n",
    "\n",
    "class Settings(object):\n",
    "    text1_maxlen = 20\n",
    "    text2_maxlen = 20\n",
    "    embedding_dim = 300\n",
    "    vocab_size = vocab_size\n",
    "    \n",
    "    hidden_sizes = 64\n",
    "    drop_out = 0.2\n",
    "    topk = 30\n",
    "    \n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-e97c66c91123>:137: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "query (InputLayer)              (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "doc (InputLayer)                (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 300)      25293600    query[0][0]                      \n",
      "                                                                 doc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 20, 128)      140160      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 20, 128)      140160      embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "match_1 (Match)                 (None, 20, 20, 1)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 400)          0           match_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 30)           0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30)           0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1, 30)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1, 30)        0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cdigitcaps (CapsuleLayer)       (None, 2, 64)        3840        primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 2)            0           cdigitcaps[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 25,577,760\n",
      "Trainable params: 284,160\n",
      "Non-trainable params: 25,293,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义网络\n",
    "query = Input(name='query', shape=(settings.text1_maxlen,))\n",
    "doc = Input(name='doc', shape=(settings.text2_maxlen,))\n",
    "\n",
    "embedding = Embedding(settings.vocab_size + 1,\n",
    "                      settings.embedding_dim,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=settings.text1_maxlen,\n",
    "                      trainable=False)\n",
    "\n",
    "q_embed = embedding(query)\n",
    "d_embed = embedding(doc)\n",
    "\n",
    "q_rep = Bidirectional(GRU(settings.hidden_sizes, return_sequences=True, dropout=settings.drop_out))(q_embed)\n",
    "d_rep = Bidirectional(GRU(settings.hidden_sizes, return_sequences=True, dropout=settings.drop_out))(d_embed)\n",
    "\n",
    "cross = Match(match_type='dot')([q_rep, d_rep])\n",
    "\n",
    "cross_reshape = Reshape((-1, ))(cross)\n",
    "\n",
    "mm_k = Lambda(lambda x: K.tf.nn.top_k(x, k=settings.topk, sorted=True)[0])(cross_reshape)\n",
    "\n",
    "pool1_flat_drop = Dropout(rate=settings.drop_out)(mm_k)\n",
    "\n",
    "primarycaps = Reshape(target_shape=[-1, 30], name=\"primarycap_reshape\")(pool1_flat_drop)\n",
    "primarycaps = Lambda(squash, name=\"primarycap_squash\")(primarycaps)\n",
    "\n",
    "digitcaps = CapsuleLayer(num_capsule=2, dim_capsule=64, routings=2, name=\"cdigitcaps\")(primarycaps)\n",
    "\n",
    "out_ = Length(name=\"capsnet\")(digitcaps)\n",
    "\n",
    "model = Model(inputs=[query, doc], outputs=out_)\n",
    "model.summary()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 323426 samples, validate on 40428 samples\n",
      "Epoch 1/100\n",
      "323426/323426 [==============================] - 536s 2ms/step - loss: 0.5681 - acc: 0.7058 - val_loss: 0.5203 - val_acc: 0.7440\n",
      "Epoch 2/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.5037 - acc: 0.7517 - val_loss: 0.4777 - val_acc: 0.7647\n",
      "Epoch 3/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.4681 - acc: 0.7738 - val_loss: 0.4548 - val_acc: 0.7796\n",
      "Epoch 4/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.4416 - acc: 0.7894 - val_loss: 0.4393 - val_acc: 0.7900\n",
      "Epoch 5/100\n",
      "323426/323426 [==============================] - 526s 2ms/step - loss: 0.4208 - acc: 0.8021 - val_loss: 0.4268 - val_acc: 0.7962\n",
      "Epoch 6/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.4023 - acc: 0.8116 - val_loss: 0.4351 - val_acc: 0.7949\n",
      "Epoch 7/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.3870 - acc: 0.8201 - val_loss: 0.4159 - val_acc: 0.8056\n",
      "Epoch 8/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.3729 - acc: 0.8291 - val_loss: 0.4122 - val_acc: 0.8100\n",
      "Epoch 9/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.3616 - acc: 0.8348 - val_loss: 0.4145 - val_acc: 0.8107\n",
      "Epoch 10/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.3510 - acc: 0.8403 - val_loss: 0.4335 - val_acc: 0.8063\n",
      "Epoch 11/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.3423 - acc: 0.8450 - val_loss: 0.4300 - val_acc: 0.8074\n",
      "Epoch 12/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.3336 - acc: 0.8501 - val_loss: 0.4132 - val_acc: 0.8152\n",
      "Epoch 13/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.3251 - acc: 0.8546 - val_loss: 0.4169 - val_acc: 0.8188\n",
      "Epoch 14/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.3183 - acc: 0.8581 - val_loss: 0.4223 - val_acc: 0.8166\n",
      "Epoch 15/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.3125 - acc: 0.8609 - val_loss: 0.4110 - val_acc: 0.8213\n",
      "Epoch 16/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.3071 - acc: 0.8641 - val_loss: 0.4201 - val_acc: 0.8168\n",
      "Epoch 17/100\n",
      "323426/323426 [==============================] - 531s 2ms/step - loss: 0.3006 - acc: 0.8678 - val_loss: 0.4197 - val_acc: 0.8190\n",
      "Epoch 18/100\n",
      "323426/323426 [==============================] - 526s 2ms/step - loss: 0.2961 - acc: 0.8694 - val_loss: 0.4322 - val_acc: 0.8189\n",
      "Epoch 19/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2916 - acc: 0.8723 - val_loss: 0.4329 - val_acc: 0.8179\n",
      "Epoch 20/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2873 - acc: 0.8740 - val_loss: 0.4252 - val_acc: 0.8186\n",
      "Epoch 21/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.2825 - acc: 0.8763 - val_loss: 0.4322 - val_acc: 0.8199\n",
      "Epoch 22/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2803 - acc: 0.8782 - val_loss: 0.4384 - val_acc: 0.8175\n",
      "Epoch 23/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2763 - acc: 0.8806 - val_loss: 0.4456 - val_acc: 0.8173\n",
      "Epoch 24/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2725 - acc: 0.8814 - val_loss: 0.4578 - val_acc: 0.8113\n",
      "Epoch 25/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2698 - acc: 0.8827 - val_loss: 0.4471 - val_acc: 0.8194\n",
      "Epoch 26/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.2668 - acc: 0.8844 - val_loss: 0.4566 - val_acc: 0.8185\n",
      "Epoch 27/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2657 - acc: 0.8853 - val_loss: 0.4372 - val_acc: 0.8188\n",
      "Epoch 28/100\n",
      "323426/323426 [==============================] - 530s 2ms/step - loss: 0.2632 - acc: 0.8865 - val_loss: 0.4425 - val_acc: 0.8228\n",
      "Epoch 29/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2600 - acc: 0.8879 - val_loss: 0.4360 - val_acc: 0.8194\n",
      "Epoch 30/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2589 - acc: 0.8890 - val_loss: 0.4490 - val_acc: 0.8189\n",
      "Epoch 31/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2547 - acc: 0.8910 - val_loss: 0.4467 - val_acc: 0.8189\n",
      "Epoch 32/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2531 - acc: 0.8910 - val_loss: 0.4451 - val_acc: 0.8170\n",
      "Epoch 33/100\n",
      "323426/323426 [==============================] - 531s 2ms/step - loss: 0.2520 - acc: 0.8922 - val_loss: 0.4359 - val_acc: 0.8235\n",
      "Epoch 34/100\n",
      "323426/323426 [==============================] - 527s 2ms/step - loss: 0.2499 - acc: 0.8938 - val_loss: 0.4446 - val_acc: 0.8235\n",
      "Epoch 35/100\n",
      "323426/323426 [==============================] - 526s 2ms/step - loss: 0.2493 - acc: 0.8936 - val_loss: 0.4485 - val_acc: 0.8196\n",
      "Epoch 36/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2484 - acc: 0.8946 - val_loss: 0.4668 - val_acc: 0.8183\n",
      "Epoch 37/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2463 - acc: 0.8959 - val_loss: 0.4384 - val_acc: 0.8220\n",
      "Epoch 38/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2442 - acc: 0.8968 - val_loss: 0.4577 - val_acc: 0.8196\n",
      "Epoch 39/100\n",
      "323426/323426 [==============================] - 485s 2ms/step - loss: 0.2427 - acc: 0.8967 - val_loss: 0.4641 - val_acc: 0.8164\n",
      "Epoch 40/100\n",
      "323426/323426 [==============================] - 486s 2ms/step - loss: 0.2411 - acc: 0.8975 - val_loss: 0.4472 - val_acc: 0.8207\n",
      "Epoch 41/100\n",
      "323426/323426 [==============================] - 486s 2ms/step - loss: 0.2389 - acc: 0.8988 - val_loss: 0.4625 - val_acc: 0.8174\n",
      "Epoch 42/100\n",
      "323426/323426 [==============================] - 485s 2ms/step - loss: 0.2394 - acc: 0.8983 - val_loss: 0.4573 - val_acc: 0.8178\n",
      "Epoch 43/100\n",
      "323426/323426 [==============================] - 487s 2ms/step - loss: 0.2395 - acc: 0.8990 - val_loss: 0.4731 - val_acc: 0.8163\n",
      "Epoch 44/100\n",
      "323426/323426 [==============================] - 487s 2ms/step - loss: 0.2385 - acc: 0.8996 - val_loss: 0.4742 - val_acc: 0.8151\n",
      "Epoch 45/100\n",
      "323426/323426 [==============================] - 491s 2ms/step - loss: 0.2367 - acc: 0.9001 - val_loss: 0.4697 - val_acc: 0.8189\n",
      "Epoch 46/100\n",
      "323426/323426 [==============================] - 494s 2ms/step - loss: 0.2367 - acc: 0.9001 - val_loss: 0.4485 - val_acc: 0.8221\n",
      "Epoch 47/100\n",
      "323426/323426 [==============================] - 485s 2ms/step - loss: 0.2347 - acc: 0.9009 - val_loss: 0.4753 - val_acc: 0.8149\n",
      "Epoch 48/100\n",
      "323426/323426 [==============================] - 485s 1ms/step - loss: 0.2349 - acc: 0.9001 - val_loss: 0.4638 - val_acc: 0.8149\n",
      "Epoch 49/100\n",
      "323426/323426 [==============================] - 485s 1ms/step - loss: 0.2331 - acc: 0.9019 - val_loss: 0.4604 - val_acc: 0.8200\n",
      "Epoch 50/100\n",
      "323426/323426 [==============================] - 498s 2ms/step - loss: 0.2328 - acc: 0.9020 - val_loss: 0.4493 - val_acc: 0.8230\n",
      "Epoch 51/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2313 - acc: 0.9026 - val_loss: 0.4431 - val_acc: 0.8234\n",
      "Epoch 52/100\n",
      "323426/323426 [==============================] - 516s 2ms/step - loss: 0.2316 - acc: 0.9029 - val_loss: 0.4607 - val_acc: 0.8230\n",
      "Epoch 53/100\n",
      "323426/323426 [==============================] - 528s 2ms/step - loss: 0.2314 - acc: 0.9029 - val_loss: 0.4562 - val_acc: 0.8224\n",
      "Epoch 54/100\n",
      "323426/323426 [==============================] - 529s 2ms/step - loss: 0.2288 - acc: 0.9043 - val_loss: 0.4588 - val_acc: 0.8201\n",
      "Epoch 55/100\n",
      "323426/323426 [==============================] - 531s 2ms/step - loss: 0.2291 - acc: 0.9035 - val_loss: 0.4502 - val_acc: 0.8183\n",
      "Epoch 56/100\n",
      "323426/323426 [==============================] - 531s 2ms/step - loss: 0.2289 - acc: 0.9036 - val_loss: 0.4488 - val_acc: 0.8214\n",
      "Epoch 57/100\n",
      "323426/323426 [==============================] - 532s 2ms/step - loss: 0.2273 - acc: 0.9049 - val_loss: 0.4730 - val_acc: 0.8158\n",
      "Epoch 58/100\n",
      "323426/323426 [==============================] - 534s 2ms/step - loss: 0.2268 - acc: 0.9047 - val_loss: 0.4574 - val_acc: 0.8209\n",
      "Epoch 59/100\n",
      "323426/323426 [==============================] - 534s 2ms/step - loss: 0.2272 - acc: 0.9051 - val_loss: 0.4682 - val_acc: 0.8145\n",
      "Epoch 60/100\n",
      "323426/323426 [==============================] - 535s 2ms/step - loss: 0.2258 - acc: 0.9056 - val_loss: 0.4494 - val_acc: 0.8223\n",
      "Epoch 61/100\n",
      "323426/323426 [==============================] - 533s 2ms/step - loss: 0.2261 - acc: 0.9048 - val_loss: 0.4697 - val_acc: 0.8181\n",
      "Epoch 62/100\n",
      "323426/323426 [==============================] - 534s 2ms/step - loss: 0.2245 - acc: 0.9059 - val_loss: 0.4535 - val_acc: 0.8221\n",
      "Epoch 63/100\n",
      "323426/323426 [==============================] - 532s 2ms/step - loss: 0.2263 - acc: 0.9056 - val_loss: 0.4701 - val_acc: 0.8200\n",
      "Epoch 64/100\n",
      "323426/323426 [==============================] - 534s 2ms/step - loss: 0.2246 - acc: 0.9055 - val_loss: 0.4756 - val_acc: 0.8196\n",
      "Epoch 65/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2237 - acc: 0.9068 - val_loss: 0.4700 - val_acc: 0.8198\n",
      "Epoch 66/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2233 - acc: 0.9061 - val_loss: 0.4674 - val_acc: 0.8199\n",
      "Epoch 67/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2228 - acc: 0.9070 - val_loss: 0.4753 - val_acc: 0.8171\n",
      "Epoch 68/100\n",
      "323426/323426 [==============================] - 526s 2ms/step - loss: 0.2217 - acc: 0.9075 - val_loss: 0.4573 - val_acc: 0.8230\n",
      "Epoch 69/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2225 - acc: 0.9072 - val_loss: 0.4898 - val_acc: 0.8160\n",
      "Epoch 70/100\n",
      "323426/323426 [==============================] - 526s 2ms/step - loss: 0.2214 - acc: 0.9076 - val_loss: 0.4698 - val_acc: 0.8225\n",
      "Epoch 71/100\n",
      "323426/323426 [==============================] - 526s 2ms/step - loss: 0.2208 - acc: 0.9079 - val_loss: 0.4833 - val_acc: 0.8165\n",
      "Epoch 72/100\n",
      "323426/323426 [==============================] - 524s 2ms/step - loss: 0.2197 - acc: 0.9084 - val_loss: 0.4742 - val_acc: 0.8217\n",
      "Epoch 73/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2194 - acc: 0.9093 - val_loss: 0.4749 - val_acc: 0.8185\n",
      "Epoch 74/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2203 - acc: 0.9083 - val_loss: 0.4726 - val_acc: 0.8196\n",
      "Epoch 75/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2187 - acc: 0.9090 - val_loss: 0.4702 - val_acc: 0.8180\n",
      "Epoch 76/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2178 - acc: 0.9089 - val_loss: 0.4833 - val_acc: 0.8181\n",
      "Epoch 77/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2186 - acc: 0.9088 - val_loss: 0.4735 - val_acc: 0.8181\n",
      "Epoch 78/100\n",
      "323426/323426 [==============================] - 525s 2ms/step - loss: 0.2184 - acc: 0.9093 - val_loss: 0.4886 - val_acc: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d04661630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime,time\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "callback_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='acc',\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_PATH,\n",
    "        monitor='val_acc',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "adadelta=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "\n",
    "model.fit([x1_train, x2_train], y_train, epochs=100, batch_size=128, callbacks=callback_list, validation_data=([x1_valid, x2_valid], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vec_pred = model.predict([x1_test, x2_test], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def to_one_hot(prob):\n",
    "    prob_shape = prob.shape\n",
    "    y_pred = np.zeros(prob_shape)\n",
    "    \n",
    "    i = 0\n",
    "    for item in prob:\n",
    "        if item[0] < item[1]:\n",
    "            y_pred[i] = np.array([0, 1])\n",
    "        else:\n",
    "            y_pred[i] = np.array([1, 0])\n",
    "        i += 1\n",
    "    return y_pred\n",
    "\n",
    "y_pred = to_one_hot(y_vec_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:80.12%\tRecall:81.7%\tF-score:80.55%\n"
     ]
    }
   ],
   "source": [
    "report = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    \n",
    "def print_prf(result):\n",
    "    precision = str(round(result[0] * 100, 2)) + \"%\"\n",
    "    recall = str(round(result[1] * 100, 2)) + \"%\"\n",
    "    f1 = str(round(result[2] * 100, 2)) + \"%\"\n",
    "    \n",
    "    strResult=\"Precision:\"+precision+\"\\tRecall:\"+recall+\"\\tF-score:\"+f1\n",
    "    print(strResult)\n",
    "    \n",
    "print_prf(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40429/40429 [==============================] - 96s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4961291324812493, 0.8129313116866312]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x1_test, x2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
